from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from dotenv import load_dotenv
import os, requests, openai, json, time, logging, random, re
from typing import Dict, List, Optional
from datetime import datetime

# ==== Setup ====
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("VendedorInteligente")

# ==== Datos ====
PRODUCTOS = {
    "empanadas": {"nombre": "Empanadas", "precio": 1500, "descripcion": "Crujientes rellenas de carne o pollo"},
    "pasteles de pollo": {"nombre": "Pasteles de pollo", "precio": 2500, "descripcion": "Suaves y con verduras frescas"},
    "pizza personal": {"nombre": "Pizza personal", "precio": 5900, "descripcion": "Deliciosa pizza individual"},
}

PROMOCIONES = ["ğŸ‰ Compra 10 empanadas y lleva 2 GRATIS!", "ğŸ”¥ Pizza + deditos por $9,900"]
SALUDOS = ["Â¡Hola! ğŸ˜Š Bienvenido a Congelados Deliciosos. Soy tu Vendedor Inteligente.", "Â¡QuÃ© gusto verte por aquÃ­! ğŸ‘‹ Soy tu Vendedor Inteligente, listo para ayudarte."]
DESPEDIDAS = ["Â¡Gracias por tu visita! Hasta pronto ğŸ˜Š", "Â¡Fue un placer ayudarte!"]
ESTADOS: Dict[str, Dict] = {}

# ==== Utilidades ====
def get_time_emoji():
    hour = datetime.now().hour
    if hour < 12: return "â˜€ï¸"
    if hour < 18: return "ğŸŒ¤ï¸"
    return "ğŸŒ™"

def formatear_respuesta_web(mensaje: str):
    return mensaje.replace("\n", "<br>")

def extraer_productos_y_cantidades(texto: str) -> List[Dict]:
    items = []
    for producto in PRODUCTOS:
        if producto in texto:
            match = re.search(r"(\d+)\s+" + re.escape(producto), texto)
            cantidad = int(match.group(1)) if match else 1
            items.append({"producto": producto, "cantidad": cantidad})
    return items

# ==== LLM fallback para intenciones complejas ====
def interpretar_mensaje_con_LLM(texto_usuario: str, estado_actual=None):
    # Resumen del pedido para contexto
    resumen = "\n".join([
        f"- {i['cantidad']} x {PRODUCTOS[i['producto']]['nombre']}"
        for i in (estado_actual.get("items", []) if estado_actual else [])
    ]) or "Ninguno."

    catalogo = "\n".join([
        f"{p['nombre']} - ${p['precio']} ({p['descripcion']})"
        for p in PRODUCTOS.values()
    ])
    nombres_disponibles = ", ".join(PRODUCTOS.keys())

    prompt = f"""
ActÃºas como "Tu Vendedor Inteligente", un asistente conversacional cÃ¡lido y profesional para una tienda de productos congelados "Congelados Deliciosos".
Objetivo: interpretar el mensaje y responder de forma humana (amable, clara y CTA).

CATÃLOGO:
{catalogo}

PEDIDO ACTUAL:
{resumen}

MENSAJE DEL CLIENTE:
"{texto_usuario}"

REGLAS IMPORTANTES (aplÃ­calas SIEMPRE):
- Si preguntan â€œÂ¿quÃ© vendes?â€, â€œÂ¿quÃ© tienes?â€, â€œÂ¿tienes mÃ¡s productos?â€ â†’ intenciÃ³n "menu" y ofrece el catÃ¡logo.
- Si piden algo que NO estÃ¡ en catÃ¡logo (p. ej. â€œbebidasâ€, â€œpostresâ€ que no tengas), responde con intenciÃ³n "no_disponible": explica con amabilidad que no lo manejas y sugiere 1-3 productos del catÃ¡logo.
- Si piden recomendaciones (reuniÃ³n, niÃ±os, algo rÃ¡pido), usa intenciÃ³n "recomendacion" con propuestas reales del catÃ¡logo.
- Si el mensaje es ambiguo, usa intenciÃ³n "no_entendido", reformula y pregunta con calidez.
- Siempre termina con una PREGUNTA amable que invite a continuar.

Devuelve SOLO JSON vÃ¡lido con esta estructura (usa solo los campos necesarios):
{{
  "intencion": "menu|pedido|saludo|despedida|pago|entrega|detalles_producto|recomendacion|no_disponible|no_entendido|confirmar",
  "items": [{{"producto":"empanadas","cantidad":2}}],        # si aplica
  "metodo": "transferencia|efectivo|",                        # si aplica (pago)
  "modo": "domicilio|tienda|",                                # si aplica (entrega)
  "tema": "empanadas|pizza|...",                              # si aplica (detalles_producto o no_disponible)
  "respuesta": "Texto conversacional con emojis (mÃ¡x 150 palabras)"
}}
"""

    try:
        resp = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Responde solo con JSON vÃ¡lido y conversacional. No incluyas explicaciones fuera del JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return json.loads(resp.choices[0].message.content)
    except Exception as e:
        logger.error("LLM fallback error", exc_info=e)
        return {
            "intencion": "no_entendido",
            "respuesta": "Lo siento ğŸ˜… no logrÃ© entender bien. Â¿PodrÃ­as decirlo de otra forma?"
        }


# ==== Endpoints ====
class MensajeWeb(BaseModel):
    texto: str
    usuario_id: str

@app.post("/webhook/demo")
async def webhook_demo(mensaje: MensajeWeb):
    uid = mensaje.usuario_id
    texto = mensaje.texto.strip().lower()

    if uid not in ESTADOS:
        ESTADOS[uid] = {"items": [], "historia": [], "timestamp": time.time(), "metodo": None, "entrega": None}
    estado = ESTADOS[uid]

    # Saludo simple
    if texto in ["hola", "buenos dÃ­as", "buenas", "hey", "hola!"]:
        respuesta = random.choice(SALUDOS) + f" {random.choice(PROMOCIONES)}"
        return {"respuesta": formatear_respuesta_web(respuesta), "estado": "saludo"}

    # MenÃº directo por keyword
    if any(k in texto for k in ["menÃº", "menu", "productos", "quÃ© vendes", "que vendes", "quÃ© tienes", "que tienes"]):
        productos = "\n".join([f"â€¢ {p['nombre']} - ${p['precio']:,}" for p in PRODUCTOS.values()])
        return {"respuesta": formatear_respuesta_web(f"AquÃ­ va nuestro menÃº ğŸ§Š:\n\n{productos}\n\nÂ¿Te antoja algo? ğŸ˜‹"), "estado": "menu"}

    # Despedida
    if any(k in texto for k in ["gracias", "chao", "adiÃ³s", "adios", "hasta luego"]):
        return {"respuesta": formatear_respuesta_web(random.choice(DESPEDIDAS)), "estado": "despedida"}

    # ExtracciÃ³n rÃ¡pida de items (num + producto en el texto)
    items_detectados = extraer_productos_y_cantidades(texto)
    if items_detectados:
        estado["items"].extend(items_detectados)
        total = sum(i["cantidad"] * PRODUCTOS[i["producto"]]["precio"] for i in estado["items"])
        desglose = "\n".join([f"- {i['cantidad']} x {PRODUCTOS[i['producto']]['nombre']} = ${i['cantidad'] * PRODUCTOS[i['producto']]['precio']:,}" for i in estado["items"]])
        respuesta = f"ğŸ›’ Â¡Perfecto! He actualizado tu pedido:\n{desglose}\n\nTotal: ${total:,}\nÂ¿Quieres agregar algo mÃ¡s o pasamos al pago? ğŸ’³"
        return {"respuesta": formatear_respuesta_web(respuesta), "estado": "pedido"}

    # === LLM conversacional ===
    resultado = interpretar_mensaje_con_LLM(texto, estado_actual=estado)
    intencion = resultado.get("intencion")
    respuesta_llm = resultado.get("respuesta", "")

    # Guarda historia
    estado["historia"].append(f"Cliente: {texto}")
    estado["historia"].append(f"Bot: {respuesta_llm}")

    # ----- Manejo por intenciÃ³n -----
    if intencion == "menu":
        # Muestra menÃº (aunque el LLM ya respondiÃ³ algo amable)
        productos = "\n".join([f"â€¢ {p['nombre']} - ${p['precio']:,}" for p in PRODUCTOS.values()])
        resp = respuesta_llm or f"AquÃ­ va nuestro menÃº ğŸ§Š:\n\n{productos}\n\nÂ¿Te antoja algo? ğŸ˜‹"
        return {"respuesta": formatear_respuesta_web(resp), "estado": "menu"}

    if intencion == "pedido":
        nuevos = resultado.get("items", [])
        if nuevos:
            # suma/merge al carrito
            for n in nuevos:
                if not n or "producto" not in n or n["producto"] not in PRODUCTOS:
                    continue
                ya = next((i for i in estado["items"] if i["producto"] == n["producto"]), None)
                if ya: ya["cantidad"] += n.get("cantidad", 1)
                else:  estado["items"].append({"producto": n["producto"], "cantidad": n.get("cantidad", 1)})
        total = sum(i["cantidad"] * PRODUCTOS[i["producto"]]["precio"] for i in estado["items"])
        desglose = "\n".join([f"- {i['cantidad']} x {PRODUCTOS[i['producto']]['nombre']} = ${i['cantidad'] * PRODUCTOS[i['producto']]['precio']:,}" for i in estado["items"]]) or "â€” vacÃ­o â€”"
        texto_resp = respuesta_llm or f"ğŸ›’ Pedido actualizado:\n{desglose}\n\nTotal: ${total:,}\nÂ¿Deseas algo mÃ¡s o pasamos al pago? ğŸ’³"
        return {"respuesta": formatear_respuesta_web(texto_resp), "estado": "pedido"}

    if intencion == "pago":
        # Respeta lo que diga el LLM si trae 'metodo'
        metodo = resultado.get("metodo")
        if metodo:
            estado["metodo"] = metodo
            return {"respuesta": formatear_respuesta_web(f"ğŸ’³ Perfecto, registrÃ© *{metodo}*. Â¿Confirmamos el pedido? âœ…"), "estado": "pago"}
        # Si no vino mÃ©todo, usa respuesta LLM como guÃ­a
        return {"respuesta": formatear_respuesta_web(respuesta_llm or "ğŸ’³ Aceptamos transferencia o efectivo. Â¿CuÃ¡l prefieres?"), "estado": "pago"}

    if intencion == "entrega":
        # Ahora soporta 'modo': domicilio | tienda
        modo = resultado.get("modo")
        if modo == "domicilio":
            estado["entrega"] = "domicilio"
            link_politica = "https://congelados-demo.com/politica-datos"
            txt = (
                f"ğŸ“¦ Â¡Listo! Enviaremos tu pedido a domicilio. "
                f"Tus datos serÃ¡n tratados segÃºn nuestras [PolÃ­ticas de Datos]({link_politica}). "
                f"Un asesor te contactarÃ¡ para coordinar el despacho. Â¿Deseas confirmar ahora? âœ…"
            )
            return {"respuesta": formatear_respuesta_web(txt), "estado": "entrega_confirmada"}
        elif modo == "tienda":
            estado["entrega"] = "tienda"
            txt = "ğŸª Perfecto, lo prepararemos para *recoger en tienda*. Â¿Quieres confirmar tu pedido ahora? âœ…"
            return {"respuesta": formatear_respuesta_web(txt), "estado": "entrega_confirmada"}
        else:
            # Si no especifica, preguntamos
            return {"respuesta": formatear_respuesta_web("Â¿Prefieres *recoger en tienda* o *envÃ­o a domicilio*? ğŸªğŸšš"), "estado": "entrega_pendiente"}

    if intencion == "detalles_producto":
        # El LLM ya trae una respuesta explicativa
        return {"respuesta": formatear_respuesta_web(respuesta_llm), "estado": "detalles_producto"}

    if intencion == "recomendacion":
        return {"respuesta": formatear_respuesta_web(respuesta_llm), "estado": "recomendacion"}

    if intencion == "no_disponible":
        # Caso â€œbebidasâ€ y similares
        return {"respuesta": formatear_respuesta_web(respuesta_llm), "estado": "no_disponible"}

    if intencion == "confirmar":
        # ConfirmaciÃ³n final de compra (demo)
        total = sum(i["cantidad"] * PRODUCTOS[i["producto"]]["precio"] for i in estado["items"])
        ESTADOS.pop(uid, None)
        cierre = (
            f"ğŸ‰ Â¡Pedido confirmado! Total: ${total:,}\n"
            f"En breve un asesor finalizarÃ¡ el proceso. Gracias por elegirnos ğŸ™Œ\n\n"
            f"PS: Este es un *demo* de Tu Vendedor Inteligente. Â¿Te gustarÃ­a tener uno asÃ­ en tu empresa por WhatsApp, web o IG? ğŸ˜‰"
        )
        return {"respuesta": formatear_respuesta_web(cierre), "estado": "confirmado"}

    # Fallback amable del LLM (no_entendido u otros)
    return {"respuesta": formatear_respuesta_web(respuesta_llm or "No te entendÃ­ bien ğŸ˜… Â¿PodrÃ­as decirlo de otra forma?"), "estado": intencion or "no_entendido"}


@app.post("/webhook/demo/reset")
async def reset(uid: str):
    ESTADOS.pop(uid, None)
    return {"status": "ok"}

@app.get("/")
async def root():
    return {"message": "Tu Vendedor Inteligente estÃ¡ activo ğŸ¤–"}

